# -*- coding: utf-8 -*-
"""Inverse_Atari.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4f5Bqmqg3Zqy4jJJzwmX9NC421aZksM
"""

# Environment
import gym
from gym.utils.play import play
#from gym.spaces import prng

# Utility 
import cv2
import numpy as np
from collections import deque
import argparse
from functools import partial
import pickle
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import normalize
import matplotlib.pyplot as plt
import tensorflow as tf

# Keras
from keras import Sequential, Model, Input
from keras.utils import to_categorical
from keras.layers import Dense, Flatten,multiply, Dropout, Reshape, Activation
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.optimizers import Adam
from keras import backend as K
from keras.preprocessing.image import ImageDataGenerator
from keras.layers.normalization import BatchNormalization
from keras import metrics
from keras.models import model_from_json
from keras.utils import plot_model

# Google Collab 
#from google.colab import files


def clipped_mse(y_true, y_pred):
        return K.mean(K.maximum(K.square(y_pred - y_true), 10), axis=-1)


def forward_model(learning_rate=0.001, decay = 0.0):
        image = Input(shape=(105, 80, 12), name='image')
        action = Input(shape=(4,), name='action')
        x = Conv2D(64, (4, 4), strides=2, activation='relu', input_shape=(105, 80, 12))(image)
        x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
        x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
        x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
        x = Flatten()(x)
        x = Dropout(0.2)(x)
        x = Dense(512, activation='relu')(x)
        x = BatchNormalization()(x)
        x = Dense(1024, activation='linear')(x)
        y = Dense(1024, activation='linear')(action)
        x = multiply([x, y])
        x = Dense(512, activation='linear')(x)
        x = Dropout(0.2)(x)
        x = Dense(2560, activation='relu')(x)
        x = BatchNormalization()(x)
        x = Reshape((5, 4, 128))(x)
        x = Conv2DTranspose(128, (3, 3), strides=2, activation='relu')(x)
        x = Conv2DTranspose(128, (3, 3), strides=2, activation='relu')(x)
        x = Conv2DTranspose(64, (6, 3), strides=2, activation='relu')(x)
        new_image = Conv2DTranspose(3, (7, 4), strides=2, activation='relu')(x)
        model = Model(inputs=[image, action], outputs=[new_image])
        model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate, decay = decay))

        return model


def inverse_model(learning_rate=0.001, decay=0.0):
      image = Input(shape = (105, 80, 12), name = 'image')
      x = Conv2D(64, (4, 4), strides=2, activation='relu', input_shape=(105, 80, 12))(image)
      x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)
      x = Conv2D(256, (3, 3), strides=2, activation='relu')(x)
      x = Conv2D(256, (3, 3), strides=2, activation='relu')(x)
      x = Flatten()(x)
      x = Dropout(0.2)(x)
      x = Dense(512, activation='relu')(x)
      x = BatchNormalization()(x)
      x = Dropout(0.2)(x)
      x = Dense(256, activation='relu')(x)
      x = BatchNormalization()(x)
      x = Dropout(0.2)(x)
      x = Dense(64, activation='relu')(x)
      x = BatchNormalization()(x)
      x = Activation('sigmoid')(x)
      action = Dense(4, activation = 'softmax')(x)
      model = Model(inputs=[image], outputs=[action])
      model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=learning_rate, decay=decay), metrics = ['accuracy'])
      return model


class MaxAndSkipEnv(gym.Wrapper):
    def __init__(self, env, skip=4):
        """Return only every `skip`-th frame"""
        gym.Wrapper.__init__(self, env)
        # most recent raw observations (for max pooling across time steps)
        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)
        self._skip       = skip

    def step(self, action):
        """Repeat action, sum reward, and max over last observations."""
        total_reward = 0.0
        done = None
        for i in range(self._skip):
            obs, reward, done, info = self.env.step(action)
            if i == self._skip - 2: self._obs_buffer[0] = obs
            if i == self._skip - 1: self._obs_buffer[1] = obs
            total_reward += reward
            if done:
                break
        # Note that the observation on the done=True frame
        # doesn't matter
        max_frame = self._obs_buffer.max(axis=0)

        return max_frame, total_reward, done, info

    def reset(self, **kwargs):
        return self.env.reset(**kwargs)


# Rescales the Image width by k and the height by l.
def repeat_upsample(rgb_array, k=1, l=1, err=[]):
    # repeat kinda crashes if k/l are zero
    if k <= 0 or l <= 0:
        if not err:
            print("Number of repeats must be larger than 0, k: {}, l: {}, returning default array!".format(k, l))
            err.append('logged')
        return rgb_array

    # repeat the pixels k times along the y axis and l times along the x axis
    # if the input image is of shape (m,n,3), the output image will be of shape (k*m, l*n, 3)

    return np.repeat(np.repeat(rgb_array, k, axis=0), l, axis=1)


# Makes an environment for simulation
# Should be exact same every time now
def make_environment(game):
    env = gym.make(game)
    #env = MaxAndSkipEnv(env,2)
    env.seed(50)
    #env.action_space.np_random.seed(0)
    #prng.seed(0)
    return env


# Makes a simple catalog for an episode ~ [observation,action,reward*,done*,info*]
# *Unless initial state
# Action Effects: 0 ~ None, 1 ~ Fire, 2 ~ Right, 3 ~ Left
def record_episode(env,num = 1):
    episodes = []
    for i in range(num):
        done = False
        lives = 5
        t_lives = 5
        episode = []
        episode.append([env.reset(),0,done,None])
        while not done:
            if lives-t_lives is True:
                action = 1
                episode[-1].insert(1, action)
                episode.append(list(env.step(action)))
                done = episode[-1][2]
                lives = t_lives
                t_lives = episode[-1][-1]['ale.lives']
            else:
                action = env.action_space.sample()
                episode[-1].insert(1,action)
                episode.append(list(env.step(action)))
                done = episode[-1][2]
                t_lives = episode[-1][-1]['ale.lives']
        episodes.append(episode)
    env.close()
    return episodes, env.action_space.n


# Used to test a random/baseline agent
def random_play(env):
    rew_total = 0
    episodes = []
    for i in range(1):
        done = False
        lives = 5
        t_lives = 5
        episode = []
        episode.append([env.reset(),0,done,None])
        while not done:
            if lives-t_lives is True:
                action = 1
                episode[-1].insert(1, action)
                episode.append(list(env.step(action)))
                done = episode[-1][2]
                lives = t_lives
                t_lives = episode[-1][-1]['ale.lives']
            else:
                action = env.action_space.sample()
                episode[-1].insert(1,action)
                episode.append(list(env.step(action)))
                done = episode[-1][2]
                t_lives = episode[-1][-1]['ale.lives']
                rew_total += episode[-1][1]
        episodes.append(episode)
    env.close()
    return rew_total


# Record a human playing the game Breakout
# Same format as record_episode
def record_human(ep,eps,obs_before,obs_after,action,rew,done,info):
    if done is False:
        ep.append((obs_before,action,rew,done))
    else:
        eps.append(np.copy(ep))
    return


# Save episodes into directory sorted by episode number
# Caution: Will overwrite without hesitation
def save_episodes(dir,eps,num = 0):
    for i in range(len(eps)):
        pickle.dump(eps[i], open(dir + str(num+i) + '.dump', 'wb'))
    return


# Load episodes from directory. You'll have to which ones you want.
def load_episodes(dir,nums):
    eps = []
    for i in nums:
        eps.append(pickle.load(open(dir + str(i) + '.dump', 'rb')))
    return eps


# Plays back the episode
def playback(frames, zoom = 3):
    for i in range(len(frames)):
        cv2.imshow('frame', repeat_upsample(frames[i][:,:,::-1], zoom, zoom))
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break


# Play Agent
def agent_play(env,model,mean,sup = [1,1,1,1], temp = 1.0):
    rew_total = 0
    for i in range(1):
        done = False
        lives = 5
        t_lives = 0
        count = 0
        frames = []
        while not done:
            if (abs(lives-t_lives) >= 1) or (count < 4):
                action = np.random.choice([0,1,2,3],1, p = [0.4,0.2,0.2,0.2])
                frame,_,done,info = env.step(action)
                frames.append(frame[::2,::2])
                if action == 1:
                    lives = t_lives
                    t_lives = info['ale.lives']
            else:
                dist = np.power(model.predict([(np.array([np.concatenate(frames[-4:],axis = 2)])-mean)/255.0])[0],temp)
                dist = dist*np.array(sup)
                dist /= np.sum(dist)
                action = np.random.choice([0,1,2,3],1, p = dist)[0]
                frame, rew, done, info = env.step(action)
                rew_total += rew
                frames.append(frame[::2, ::2])
                t_lives = info['ale.lives']
            cv2.imshow('frame', repeat_upsample(frames[count][:, :, ::-1], 6, 6))
            if cv2.waitKey(30) & 0xFF == ord('q'):
                break
            count += 1
    env.close()
    return rew_total


# Prepares the data by splitting frames into observation and target
# Makes images black and white and rescales to be half of the original size
def forward_data(episodes,n_actions = 4):
    stacks = []
    actions = []
    targets = []
    for j in range(len(episodes)):
        frames,inputs,_,_ = zip(*episodes[j])
        frames = list(frames)
        for i in range(len(episodes[j])):
            frames[i] = frames[i][::2,::2]

        inputs = np.array(inputs)
        inputs[inputs == 1] = 0

        stack = []
        action = []
        target = []
        for i in range(len(episodes[j])-4):
            stack.append(np.concatenate(np.array(frames[i:i+2]),axis = 2))
            action.append(inputs[i+1])
            target.append(np.concatenate(np.array(frames[i+2:i+4]),axis = 2))

        stacks += stack
        actions += action
        targets += target

    return np.array(stacks),np.array(actions),np.array(targets)
  

# Return frame/action pairs
def inverse_data(episodes,n_actions = 4):
    stacks = []
    actions = []
    for j in range(len(episodes)):
        frames,inputs,_,_ = zip(*episodes[j])
        frames = list(frames)
        for i in range(len(episodes[j])):
            frames[i] = frames[i][::2,::2]

        inputs = np.array(inputs)
        inputs[inputs == 1] = 0

        stack = []
        action = []
        for i in range(len(episodes[j])-3):
            stack.append(np.concatenate(np.array(frames[i:i+4]),axis = 2))
            action.append(inputs[i+1])

        stacks += stack
        actions += action

    return np.array(stacks),np.array(actions)


# Data integrity tool. Shows that observations and target are logically constructed
def validate_data(d,a,t):
    for i in range(4):
        cv2.imshow('frame', repeat_upsample(np.array(d[:,:,i]), 3, 3))
        if cv2.waitKey(3000) & 0xFF == ord('q'):
            break
    print('Selected Action ' + str(a[0]) + '\n')
    cv2.imshow('frame', repeat_upsample(t, 3, 3))
    if cv2.waitKey(3000) & 0xFF == ord('q'):
        return


def make_confusion_plot(i_model,f_model,c_model,random_episodes,human_episodes):

    print("Computing i_model confusion")

    fig, ax = plt.subplots(nrows = 2, ncols = 3, constrained_layout = True)

    # Make Confusion Matrix
    data,actions = inverse_data(random_episodes)
    r_score = np.argmax(i_model.predict([(data - np.mean(data, axis=0)) / 255.0]), axis=1)
    r_score[r_score == 1] = 0
    r_conf = confusion_matrix(actions, r_score)
    r_conf = normalize(r_conf,norm = 'l1')
    print("Random Score is " + str(np.trace(r_conf) / np.sum(r_conf)))
    print(r_conf)
    data, actions = inverse_data(human_episodes)
    h_score = np.argmax(i_model.predict([(data - np.mean(data, axis=0)) / 255.0]), axis=1)
    h_conf = confusion_matrix(actions, h_score)
    h_conf = normalize(h_conf, norm = 'l1')
    print("Human Score is " + str(np.trace(h_conf) / np.sum(h_conf)))
    print(h_conf)

    im = ax[0,0].imshow(r_conf)
    ax[0,0].set_xticks(np.arange(3))
    ax[0,0].set_yticks(np.arange(3))
    ax[0,0].set_xticklabels(['None', 'Right', 'Left'])
    ax[0,0].set_yticklabels(['None', 'Right', 'Left'])
    ax[0,0].set_title("Random Inverse")

    ax[1, 0].imshow(h_conf)
    ax[1, 0].set_xticks(np.arange(3))
    ax[1, 0].set_yticks(np.arange(3))
    ax[1, 0].set_xticklabels(['None', 'Right', 'Left'])
    ax[1, 0].set_yticklabels(['None', 'Right', 'Left'])
    ax[1, 0].set_title("Human Inverse")

    print("Computing f_model confusion")

    data, actions, targets = forward_data(random_episodes)
    sess = tf.Session()
    r_score = []
    pick = [0, 0, 0, 0]
    idx_actions = np.random.randint(0,len(actions), size = 100)
    actions = actions[idx_actions]
    for j in range(100):
        frames = (data[j] - np.mean(data, axis=0)) / 255.0
        frames = np.tile(frames, (4, 1, 1, 1))
        pick = np.sum(clipped_mse(f_model.predict([frames, np.arange(0, 4)])[:,:,:,3:6], targets[j][:,:,3:6]).eval(session=sess), axis=(1, 2))
        r_score.append(np.argmin(pick))
    r_score = np.array(r_score)
    r_score[r_score == 1] = 0
    actions[actions == 1] = 0
    r_conf = confusion_matrix(actions, r_score)
    r_conf = normalize(r_conf,norm = 'l1')
    print("Random Score is " + str(np.trace(r_conf) / np.sum(r_conf)))
    print(r_conf)

    data, actions, targets = forward_data(human_episodes)
    sess = tf.Session()
    h_score = []
    pick = [0, 0, 0, 0]
    idx_actions = np.random.randint(0, len(actions), size=100)
    actions = actions[idx_actions]
    for j in range(100):
        frames = (data[j] - np.mean(data, axis=0)) / 255.0
        frames = np.tile(frames, (4, 1, 1, 1))
        pick = np.sum(clipped_mse(f_model.predict([frames, np.arange(0, 4)])[:,:,:,3:6], targets[j][:,:,3:6]).eval(session=sess),axis=(1, 2))
        h_score.append(np.argmin(pick))
    h_score = np.array(h_score)
    h_score[h_score == 1] = 0
    actions[actions == 1] = 0
    h_conf = confusion_matrix(actions, h_score)
    h_conf = normalize(h_conf, norm = 'l1')
    print("Human Score is " + str(np.trace(h_conf) / np.sum(h_conf)))
    print(h_conf)

    ax[0, 1].imshow(r_conf)
    ax[0, 1].set_xticks(np.arange(3))
    ax[0, 1].set_yticks(np.arange(3))
    ax[0, 1].set_xticklabels(['None', 'Right', 'Left'])
    ax[0, 1].set_yticklabels(['None', 'Right', 'Left'])
    ax[0, 1].set_title("Random Forward")

    ax[1, 1].imshow(h_conf)
    ax[1, 1].set_xticks(np.arange(3))
    ax[1, 1].set_yticks(np.arange(3))
    ax[1, 1].set_xticklabels(['None', 'Right', 'Left'])
    ax[1, 1].set_yticklabels(['None', 'Right', 'Left'])
    ax[1, 1].set_title("Human Forward")

    print("Computing c_model confusion")

    # Make Confusion Matrix
    data, actions = inverse_data(random_episodes)
    data = data[:-2]
    actions = actions[2:]
    r_score = np.argmax(c_model.predict([(data - np.mean(data, axis=0)) / 255.0]), axis=1)
    r_score[r_score == 1] = 0
    r_conf = confusion_matrix(actions, r_score)
    r_conf = normalize(r_conf)
    print("Random Score is " + str(np.trace(r_conf) / np.sum(r_conf)))
    print(r_conf)
    data, actions = inverse_data(human_episodes)
    data = data[:-2]
    actions = actions[2:]
    h_score = np.argmax(c_model.predict([(data - np.mean(data, axis=0)) / 255.0]), axis=1)
    h_score[h_score == 1] = 0
    h_conf = confusion_matrix(actions, h_score)
    h_conf = normalize(h_conf,norm = 'l1')
    print("Human Score is " + str(np.trace(h_conf) / np.sum(h_conf)))
    print(h_conf)

    ax[0, 2].imshow(r_conf)
    ax[0, 2].set_xticks(np.arange(3))
    ax[0, 2].set_yticks(np.arange(3))
    ax[0, 2].set_xticklabels(['None', 'Right', 'Left'])
    ax[0, 2].set_yticklabels(['None', 'Right', 'Left'])
    ax[0, 2].set_title("Random Clone")

    ax[1, 2].imshow(h_conf)
    ax[1, 2].set_xticks(np.arange(3))
    ax[1, 2].set_yticks(np.arange(3))
    ax[1, 2].set_xticklabels(['None', 'Right', 'Left'])
    ax[1, 2].set_yticklabels(['None', 'Right', 'Left'])
    ax[1, 2].set_title("Human Clone")

    fig.colorbar(im, ax=list(ax.flatten()))
    plt.show()

    return


# Shrink image from (400,600,3) -> (105,80,3)
def wrap_image(img):
    return np.resize(np.transpose(img[::5,::6],(1,0,2)),(105,80,3))


# Push-Cart Evaluation
def model_evaluate(model, num_episodes = 30):
    """
        Evaluate a RL agent
        :param model: (BaseRLModel object) the RL Agent
        :param num_episodes: (int) number of episodes to evaluate it
        :return: (float) Mean reward for the last num_episodes and episode data
    """

    # This function will only work for a single Environment
    env = gym.make('CartPole-v1')
    all_episode_rewards = []
    episodes = []
    for i in range(num_episodes):
        episode_rewards = []
        episode = []
        done = False
        obs = env.reset()
        empty_img = env.render(mode='rgb_array')
        print(wrap_image(empty_img).shape)
        episode.append([wrap_image(empty_img), 0, done, None])
        count = 0
        frames = []
        frames.append(wrap_image(empty_img))
        frames.append(wrap_image(empty_img))
        frames.append(wrap_image(empty_img))
        frames.append(wrap_image(empty_img))
        while not done:
            # _states are only useful when using LSTM policies
            # action, _states = model.predict(obs)
            if count < 4:
                action = env.action_space.sample()
                _ , _, done, info = env.step(action)
                frame = env.render(mode='rgb_array')
                frames.append(wrap_image(frame))
            else:
                print('here')
                dist = model.predict([np.array([np.concatenate(frames[-4:], axis=2)])])[0]
                dist[2] = 0
                dist[3] = 0
                dist /= np.sum(dist)
                action = np.random.choice([0, 1, 2, 3], 1, p=dist)[0]
                print(action)
                # action = env.action_space.sample()
                # here, action, rewards and dones are arrays
                # because we are using vectorized env
                obs, reward, done, info = env.step(action)
                img = env.render(mode='rgb_array')
                episode_rewards.append(reward)
                episode[-1].insert(1,action)
                episode.append([wrap_image(img), reward, done, info])
            count += 1

        env.close()
        all_episode_rewards.append(sum(episode_rewards))
        episodes.append(episode)

    mean_episode_reward = np.mean(all_episode_rewards)
    print("Mean reward:", mean_episode_reward, "Num episodes:", num_episodes)

    return mean_episode_reward, episodes


env = make_environment('CartPole-v1')
#print(actions.shape)
#save_episodes("Trained_Model/",episodes,num = 15)
#data,actions,targets = forward_data(episodes)
#playback(targets)

# Record a human playing the game and store data into episodes
# Do NOT play more than a single complete episode#
#episode = []
#episodes = []
#play(env,zoom = 8,callback = partial(record_human,episode,episodes), fps = 30)
#save_episodes("Human_Model/",episodes,num = 40)

# Load human episode and calculate stat(s)
'''total_rew = []
for i in range(20):
    episodes = load_episodes("Human_Model/",[i])
    _,_,rew,_ = zip(*episodes[0])
    rew = rew
    print(sum(list(rew)))
    total_rew.append(sum(list(rew)))
print("Mean Reward: " + str(np.mean(total_rew)))'''
#print(len(episodes[0]))
#data,_ = inverse_data(episodes)
#frames = pickle.load(open('Test_Models/' + 'clone_example' + '.dump', 'rb'))
#playback(frames)

# Optionally load json and create model
load_model = True
if load_model is True:
    json_file = open('Production_Models/final_i_model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    i_model = model_from_json(loaded_model_json)
    # load weights into new model
    i_model.load_weights("Production_Models/final_i_model.h5")
    print("Loaded model from disk")

    # View data and target to verify integrity
    #validate_data(data[4], actions[4:])'''

# Optionally load json and create model
load_model = True
if load_model is True:
    json_file = open('Production_Models/f_model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    f_model = model_from_json(loaded_model_json)
    # load weights into new model
    f_model.load_weights("Production_Models/f_model.h5")
    print("Loaded model from disk")

    # View data and target to verify integrity
    #validate_data(data[4], actions[4:])'''

# Optionally load json and create model
load_model = True
if load_model is True:
    json_file = open('Test_Models/c_model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    c_model = model_from_json(loaded_model_json)
    # load weights into new model
    c_model.load_weights("Test_Models/c_model_push.h5")
    print("Loaded model from disk")

    # View data and target to verify integrity
    #validate_data(data[4], actions[4:])'''

print('got here')
model_evaluate(c_model, num_episodes=1)

#random_episodes, n_actions = record_episode(env,num = 5)
#human_episodes = load_episodes("Human_Model/",[7])

#make_confusion_plot(i_model, f_model, c_model, random_episodes, human_episodes)

# Display Raw Predictions
'''new_frames = model.predict([(data-np.mean(data,axis = 0))/255.0,actions])
print(np.shape(new_frames))
new_frames = new_frames.astype('uint8')
playback(new_frames[:,:,:,3:6], zoom = 8)'''

# Do Bootstrapping and plot loss vs. time
'''sess = tf.Session()
zoom = 8
losses = []
for i in range(1):
    loss = []
    episodes, n_actions = record_episode(env, num=1)
    # episodes = load_episodes("Human_Model/",[2])
    data, actions, targets = forward_data(episodes)
    frames = data[0]
    frames = np.tile(frames, (1, 1, 1, 1))
    actions = actions[0:100]
    super_frames = []
    for j in range(len(actions)):
        pick = f_model.predict([(frames-np.mean(data,axis = 0))/255.0,np.array([actions[j]])])
        frames = np.array([np.concatenate([np.copy(frames[0,:,:,3:6]),np.copy(pick[0,:,:,0:3])],axis = 2)])
        loss.append(np.mean(clipped_mse(pick[:, :, :, 3:6], targets[j][:, :, 3:6]).eval(session=sess),axis=(1, 2))[0])
        pick = pick.astype('uint8')
        cv2.imshow('frame', repeat_upsample(pick[0][:, :, 0:3], zoom, zoom))
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break
        super_frames.append(pick[0][:,:,0:3])
    print(loss)
    losses.append(np.array(loss))

import imageio
imageio.mimsave("forward_movie.gif", super_frames, fps=30)'''


'''fig, ax = plt.subplots(nrows = 1, ncols = 3, constrained_layout = True)
print(super_frames[0].shape)
ax[0].imshow(super_frames[0])
ax[1].imshow(super_frames[1])
ax[2].imshow(super_frames[2])
plt.show()'''

'''print(list(sum(losses)/5))
plt.plot(list(range(0,30)),list(sum(losses)/5))
plt.title("Loss vs. Time Step")
plt.xlabel("Forecast Length")
plt.ylabel("Loss")
plt.show()'''



# Evaluate learned agent
'''mu = pickle.load(open('Production_Models/' + 'mu' + '.dump', 'rb'))
rew = []
for i in range(1):
    env = gym.make("BreakoutNoFrameskip-v4")
    env = gym.wrappers.Monitor(env,'Test_Recording',force = True)
    env = MaxAndSkipEnv(env, 2)
    env.reset()
    temp = agent_play(env, c_model, mu, sup = [1,0,2,1])
    rew.append(temp)
    print(np.mean(rew))
env.close()
print("Mean Reward: " + str(np.mean(rew)))
print("Median Reward: " + str(np.median(rew)))'''

# Evaluate random agent
'''rew = []
for i in range(30):
    print(i)
    env.reset()
    rew.append(random_play(env,))
print("Average Reward: " + str(np.mean(rew)))'''
